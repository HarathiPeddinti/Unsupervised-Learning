# -*- coding: utf-8 -*-
"""Clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HSbBQZ4iqezLrqiqUpTfo4tl9aNuEwzY

K-**Means** **bold text**
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Generate synthetic dataset
X, _ = make_blobs(n_samples=500, centers=4, cluster_std=0.60, random_state=0)

d1 = make_blobs()
print(d1[0].shape)

# Elbow Method
wcss = []
K = range(2, 11)

for k in K:
    kmeans = KMeans(n_clusters=k, init="k-means++", n_init=10, max_iter=300, random_state=42)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

# Plot Elbow Curve
plt.plot(K, wcss, marker='o')
plt.xlabel("Number of Clusters (K)")
plt.ylabel("WCSS (Inertia)")
plt.title("Elbow Method")
plt.show()

# Silhouette Score

silhouette_scores = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, init="k-means++", n_init=10, max_iter=300, random_state=42)
    labels = kmeans.fit_predict(X)
    sil_score = silhouette_score(X, labels)
    silhouette_scores.append(sil_score)
    print(f"For k = {k}, Silhouette Score = {sil_score:.4f}")

# Best K based on Silhouette Score
best_k = K[np.argmax(silhouette_scores)]
print(f"\nBest K (by Silhouette Score): {best_k}")

# Visualize Final Clusters

kmeans = KMeans(n_clusters=best_k, init="k-means++", n_init=10, max_iter=300, random_state=42)
y_kmeans = kmeans.fit_predict(X)

plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap="viridis")
centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c="red", s=200, marker="X", label="Centroids")
plt.title(f"K-Means Clustering (Best K = {best_k})")
plt.legend()
plt.show()

"""**Hierarchical Agglomerative Clustering**"""

import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import AgglomerativeClustering
import scipy.cluster.hierarchy as sch

X, _ = make_blobs(n_samples=200, centers=4, cluster_std=0.60, random_state=1)

# Plot Dendrogram
plt.figure(figsize=(8, 4))
dendrogram = sch.dendrogram(sch.linkage(X, method='ward'))
plt.title("Dendrogram")
plt.xlabel("Data Points")
plt.ylabel("Euclidean Distance")
plt.show()

# Plot Dendrogram
plt.figure(figsize=(8, 4))
dendrogram = sch.dendrogram(sch.linkage(X, method='complete'))
plt.title("Dendrogram")
plt.xlabel("Data Points")
plt.ylabel("Euclidean Distance")
plt.show()

# Plot Dendrogram
plt.figure(figsize=(8, 4))
dendrogram = sch.dendrogram(sch.linkage(X, method='average'))
plt.title("Dendrogram")
plt.xlabel("Data Points")
plt.ylabel("Euclidean Distance")
plt.show()

# Plot Dendrogram
plt.figure(figsize=(8, 4))
dendrogram = sch.dendrogram(sch.linkage(X, method='single'))
plt.title("Dendrogram")
plt.xlabel("Data Points")
plt.ylabel("Euclidean Distance")
plt.show()

agg_clust = AgglomerativeClustering(n_clusters=4, linkage='ward')
labels = agg_clust.fit_predict(X)

# Plot Clusters
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.title("Agglomerative Clustering")
plt.show()

"""**DBSCAN**"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons
from sklearn.cluster import DBSCAN

# Generate dataset (non-linear shape)
X, _ = make_moons(n_samples=300, noise=0.05, random_state=42)

# Apply DBSCAN
db = DBSCAN(eps=0.2, min_samples=3, metric='euclidean')
labels = db.fit_predict(X)

# Plot clusters
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='plasma', s=50)
plt.title("DBSCAN Clustering")
plt.show()

"""**Mean-shift Clustering**"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import MeanShift, estimate_bandwidth

# Generate synthetic dataset (make_moons)
X, y = make_moons(n_samples=500, noise=0.1, random_state=42)

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Estimate bandwidth
bandwidth = estimate_bandwidth(X_scaled, quantile=0.2, n_samples=500)

# Apply Mean Shift clustering
ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)
ms.fit(X_scaled)

# Get cluster labels
labels = ms.labels_
cluster_centers = ms.cluster_centers_
n_clusters = len(np.unique(labels))

print(f"Estimated number of clusters: {n_clusters}")

# Plot the clusters
plt.figure(figsize=(8, 6))
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis', s=30)
plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1],
            c='red', marker='X', s=200, label='Cluster Centers')
plt.title("Mean Shift Clustering on make_moons Dataset")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()

"""**Specttral Clustering**"""

import matplotlib.pyplot as plt
from sklearn.datasets import make_moons
from sklearn.cluster import SpectralClustering
from sklearn.preprocessing import StandardScaler

# Generate dataset
X, y = make_moons(n_samples=500, noise=0.1, random_state=42)

# Scale the dataset
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply Spectral Clustering
spectral = SpectralClustering(
    n_clusters=2,
    affinity='rbf',
    assign_labels='kmeans',
    random_state=42
)

labels = spectral.fit_predict(X_scaled)

# Plot results
plt.figure(figsize=(8,6))
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis', s=30)
plt.title("Spectral Clustering on make_moons Dataset")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()